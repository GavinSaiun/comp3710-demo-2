import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from sklearn.datasets import fetch_lfw_people
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import numpy as np
import time

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
if not torch.cuda.is_available():
    print("Warning CUDA not Found. Using CPU")

# Hyper-parameters
num_epochs = 8 # The number of times the model will iterate over the training dataset
learning_rate = 1e-3
batch_size = 128 # the number of samples before backpropogration
num_classes = 7  # Number of classes in LFW dataset
channels = 1  # Since images are grayscale

# Data loading and preprocessing
lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)
X = lfw_people.images
Y = lfw_people.target

print("X_min:", X.min(), "X_max:", X.max())
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)

# Add channel dimension
X_train = X_train[:, np.newaxis, :, :]
X_test = X_test[:, np.newaxis, :, :]
print("X_train shape:", X_train.shape)

# Convert data to PyTorch tensors
X_train = torch.tensor(X_train, dtype=torch.float32)
X_test = torch.tensor(X_test, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.long)
y_test = torch.tensor(y_test, dtype=torch.long)

# Data loaders, wraps dataset into batches for easy access, shuffles the data at each epoch
train_loader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(X_train, y_train),
                                           batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=torch.utils.data.TensorDataset(X_test, y_test),
                                          batch_size=batch_size, shuffle=False)

# Define the CNN model
class ConvNetwork(nn.Module):
    def __init__(self, num_classes=7):
        super(ConvNetwork, self).__init__()
        self.layer1 = nn.Sequential(
            # Applies Convolution with 32 filters and kernel size of 3x3
            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),
            # Batch Normalization
            nn.BatchNorm2d(32),
            # ReLu activation
            nn.ReLU(),
            # Max Pooling to reduce the spatial dimensions to 2x2
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.layer2 = nn.Sequential(
            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        # Dense Layer, every neuron is connected to every neuron in the previous

        # first fully connected layer parameter(num_input_neurons, num_output_neurons)
        # 32 * 12 * 9 = number of output channels * height of feature * width, 128 = number of neurons in layer
        self.fc1 = nn.Linear(32 * 12 * 9, 128)  # Adjust according to your image size

        # 128, 7
        self.fc2 = nn.Linear(128, num_classes)

    # Forward Pass
    def forward(self, x):
        # Apply convolutional layers to extract and refine features   
        out = self.layer1(x)
        out = self.layer2(out)
        # Flatten the output tensor for dense layers
        out = out.view(out.size(0), -1)  # Flatten the output for dense layers
        out = self.fc1(out)
        out = self.fc2(out)
        return out

model = ConvNetwork(num_classes).to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Training the model
print("> Training")
model.train()
start = time.time()

# Loop the training dataset for each epoch
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        # Move images and labels to GPU 
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass
        outputs = model(images) # Get predictions
        loss = criterion(outputs, labels) # compute loss

        # Backward and optimize
        optimizer.zero_grad() # reset gradient for back propagation
        loss.backward()
        optimizer.step() # updates model's weight

        if (i + 1) % 100 == 0:
            print("Epoch [{}/{}], Step [{}/{}], Loss: {:.5f}".format(epoch + 1, num_epochs, i + 1, len(train_loader), loss.item()))

end = time.time()
elapsed = end - start
print(f"Training took {elapsed} secs or {elapsed/60} mins in total")

# Testing the model
print("> Testing")
model.eval()
start = time.time()

with torch.no_grad():
    correct = 0
    total = 0
    all_predictions = []
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)

        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        all_predictions.extend(predicted.cpu().numpy())

    accuracy = 100 * correct / total
    print(f'Test Accuracy: {accuracy:.2f} %')
    print(classification_report(y_test, all_predictions, target_names=lfw_people.target_names))

end = time.time()
elapsed = end - start
print(f"Testing took {elapsed} secs or {elapsed/60} mins in total")
